# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1opu6xXRt6OGLaT5YuQjcSm-5TVWhkHIO
"""

!pip install pyspark dask matplotlib seaborn

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

print(type(df))         # Check original type
df_pandas = df.toPandas()
print(type(df_pandas))  # Should now be <class 'pandas.core.frame.DataFrame'>
print(df_pandas.head()) # Preview the first few rows

from pyspark.sql.functions import col, when, count
from pyspark.sql.functions import desc
from pyspark.sql.functions import regexp_replace

#Importing Pyspark Libraries
from pyspark.sql import SparkSession
from pyspark.sql.functions import col,mean,when

#Importing Dask
import dask.dataframe as dd

#Importing Visualization Libraries
import matplotlib.pyplot as plt
import seaborn as sns

spark=SparkSession.builder.appName("BigDataAnalysis").getOrCreate()

from google.colab import drive
drive.mount('/content/drive')

#Loading the dataset
file_path="/content/drive/MyDrive/cleaned_reviews.csv"
df=spark.read.csv(file_path,header=True,inferSchema=True)
df.show(5)

# Print schema
df.printSchema()

# Count total rows
print(f"Total Rows: {df.count()}")

# Check missing values
df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()

#Distribution of Sentiments
df.groupBy("sentiments").count().orderBy(desc("count")).show()

#Average Review Score per Sentiment
df.groupBy("sentiments").agg(mean("review_score").alias("avg_score")).show()

#Top 10 longest reviews
df.orderBy(desc("cleaned_review_length")).select("cleaned_review", "cleaned_review_length").show(10, truncate=False)

#Removing Special Characters from Reviews
df = df.withColumn("cleaned_review", regexp_replace(col("cleaned_review"), "[^a-zA-Z0-9 ]", ""))
df.show(5)

#Filling missing values
df = df.fillna({"cleaned_review": "Unknown", "review_score": df.select(mean(col("review_score"))).collect()[0][0]})
df.show(5)

#Distribution of Sentiments
plt.figure(figsize=(8,5))
sns.countplot(x="sentiments", data=df_pandas, palette="viridis")
plt.title("Sentiment Distribution", fontsize=14)
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

#Review Score Distribution
plt.figure(figsize=(8,5))
sns.histplot(df_pandas["review_score"].dropna(), bins=5, kde=True, color="blue")  # Drop NaN values
plt.title("Review Score Distribution", fontsize=14)
plt.xlabel("Review Score")
plt.ylabel("Count")
plt.show()

#Average Review Score per Sentiment
avg_scores = df_pandas.groupby("sentiments")["review_score"].mean().reset_index()
plt.figure(figsize=(8,5))
sns.barplot(x="sentiments", y="review_score", data=avg_scores, palette="coolwarm")
plt.title("Average Review Score per Sentiment", fontsize=14)
plt.xlabel("Sentiment")
plt.ylabel("Average Score")
plt.show()

#Review length vs Sentiment
df_pandas['cleaned_review_length'] = pd.to_numeric(df_pandas['cleaned_review_length'], errors='coerce')
plt.figure(figsize=(8,5))
sns.boxplot(x="sentiments", y="cleaned_review_length", data=df_pandas, palette="magma")
plt.title("Review Length vs. Sentiment", fontsize=14)
plt.xlabel("Sentiment")
plt.ylabel("Review Length")
plt.show()

















